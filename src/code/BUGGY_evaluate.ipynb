{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "606a6162-6314-4285-84d4-cfd0c6bad19c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json, os, re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9745aceb-e1d3-45a4-bf20-2cf364212169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_files(directory_path):\n",
    "    json_data = {}\n",
    "    invalid_files = []\n",
    "    \n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.json'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            try:\n",
    "                with open(file_path, 'r') as file:\n",
    "                    data = json.load(file)\n",
    "                    json_data[filename] = data\n",
    "            except json.JSONDecodeError:\n",
    "                invalid_files.append(filename)\n",
    "    \n",
    "    return json_data, invalid_files\n",
    "\n",
    "def read_csv_files(directory_path):\n",
    "    csv_data = {}\n",
    "    invalid_files = []\n",
    "    \n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            try:\n",
    "                data = pd.read_csv(file_path)\n",
    "                csv_data[filename] = data\n",
    "            except pd.errors.EmptyDataError:\n",
    "                invalid_files.append(filename)\n",
    "            except pd.errors.ParserError:\n",
    "                invalid_files.append(filename)\n",
    "    \n",
    "    return csv_data, invalid_files\n",
    "\n",
    "\n",
    "def get_json_lines(input_dict):\n",
    "    output_dict = {}\n",
    "    \n",
    "    for key, list_of_dicts in input_dict.items():\n",
    "        transformed_list = []\n",
    "        \n",
    "        for inner_dict in list_of_dicts:\n",
    "            if 'vulnerableLines' in inner_dict:\n",
    "                vulnerable_lines = inner_dict['vulnerableLines']\n",
    "                \n",
    "                # Split the vulnerableLines value\n",
    "                parts = vulnerable_lines.split('-')\n",
    "                start = int(parts[0])\n",
    "                end = int(parts[1]) if len(parts) > 1 else start\n",
    "                \n",
    "                # Create a new dictionary with start and end\n",
    "                new_dict = {\n",
    "                    'start': start,\n",
    "                    'end': end\n",
    "                }\n",
    "                \n",
    "                transformed_list.append(new_dict)\n",
    "        \n",
    "        output_dict[key[:-5]] = transformed_list\n",
    "    \n",
    "    return output_dict\n",
    "\n",
    "def get_csv_lines(input_dict):\n",
    "    output_dict = {}\n",
    "    \n",
    "    for key, df in input_dict.items():\n",
    "        transformed_list = []\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            start = row['loc']\n",
    "            end = start + row['length'] - 1\n",
    "            \n",
    "            new_dict = {\n",
    "                'start': start,\n",
    "                'end': end\n",
    "            }\n",
    "            \n",
    "            transformed_list.append(new_dict)\n",
    "        \n",
    "        output_dict[key[:-4]] = transformed_list\n",
    "    \n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1f3ec3bc-9b27-480a-938a-779212f1dfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_enclosure(actual_lines, gt_lines):\n",
    "    actual_overlap = {}\n",
    "    gt_found = {}\n",
    "\n",
    "    for key in actual_lines:\n",
    "        # Initialize lists with 0s\n",
    "        actual_overlap[key] = [0] * len(actual_lines[key])\n",
    "        gt_found[key] = [0] * len(gt_lines[key])\n",
    "\n",
    "        for i, actual_interval in enumerate(actual_lines[key]):\n",
    "            start_actual = actual_interval['start']\n",
    "            end_actual = actual_interval['end']\n",
    "\n",
    "            for j, gt_interval in enumerate(gt_lines.get(key, [])):\n",
    "                start_gt = gt_interval['start']\n",
    "                end_gt = gt_interval['end']\n",
    "\n",
    "                if start_gt <= start_actual and end_gt >= end_actual:\n",
    "                    actual_overlap[key][i] = 1\n",
    "                    gt_found[key][j] =1#+= 1\n",
    "\n",
    "    return actual_overlap, gt_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c84116c8-226a-44a7-a96a-ae5b82e2618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tracker:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.reset()\n",
    "\n",
    "    def update(self, value):\n",
    "        self.values.append(value)\n",
    "\n",
    "    def reset(self):\n",
    "        self.values = []\n",
    "        \n",
    "    def len(self):\n",
    "        return len(self.values)\n",
    "\n",
    "    def avg(self):\n",
    "        return sum(self.values)/len(self.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "485e5d3c-4498-4080-a396-bd39dfc65c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class evaluate:\n",
    "    def __init__(self, actual, gt):\n",
    "        self.FP = actual.count(0)\n",
    "        self.FN = gt.count(0)\n",
    "        self.TP = actual.count(1)\n",
    "        self.precision = self.TP / (self.TP + self.FP) if (self.TP + self.FP) > 0 else 0\n",
    "        self.recall = self.TP / (self.TP + self.FN) if (self.TP + self.FN) > 0 else 0\n",
    "        if (self.precision + self.recall) > 0:\n",
    "            self.f1_score = 2 * (self.precision * self.recall) / (self.precision + self.recall)\n",
    "        else:\n",
    "            self.f1_score = 0\n",
    "\n",
    "\n",
    "    def display(self):\n",
    "        print(f\"Precision: {self.precision:.3f}\")\n",
    "        print(f\"Recall: {self.recall:.3f}\")\n",
    "        print(f\"F1 Score: {self.f1_score:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b91aad10-8a14-4970-b5fa-6c6ba61da842",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------10-------------------------\n",
      "Precision: 1.000\n",
      "Recall: 1.000\n",
      "F1 Score: 1.000\n",
      "-------------------------11-------------------------\n",
      "Precision: 1.000\n",
      "Recall: 1.000\n",
      "F1 Score: 1.000\n",
      "-------------------------12-------------------------\n",
      "Precision: 1.000\n",
      "Recall: 1.000\n",
      "F1 Score: 1.000\n",
      "-------------------------13-------------------------\n",
      "Precision: 1.000\n",
      "Recall: 1.000\n",
      "F1 Score: 1.000\n",
      "-------------------------14-------------------------\n",
      "Precision: 1.000\n",
      "Recall: 1.000\n",
      "F1 Score: 1.000\n",
      "-------------------------15-------------------------\n",
      "Precision: 1.000\n",
      "Recall: 1.000\n",
      "F1 Score: 1.000\n",
      "-------------------------16-------------------------\n",
      "Precision: 1.000\n",
      "Recall: 0.976\n",
      "F1 Score: 0.988\n",
      "-------------------------17-------------------------\n",
      "Precision: 0.900\n",
      "Recall: 0.900\n",
      "F1 Score: 0.900\n",
      "-------------------------18-------------------------\n",
      "Precision: 0.977\n",
      "Recall: 0.977\n",
      "F1 Score: 0.977\n",
      "-------------------------19-------------------------\n",
      "Precision: 1.000\n",
      "Recall: 1.000\n",
      "F1 Score: 1.000\n",
      "-------------------------2-------------------------\n",
      "Precision: 1.000\n",
      "Recall: 1.000\n",
      "F1 Score: 1.000\n",
      "-------------------------20-------------------------\n",
      "Precision: 1.000\n",
      "Recall: 0.968\n",
      "F1 Score: 0.984\n",
      "-------------------------21-------------------------\n",
      "Precision: 0.931\n",
      "Recall: 1.000\n",
      "F1 Score: 0.964\n",
      "-------------------------25-------------------------\n",
      "Precision: 1.000\n",
      "Recall: 1.000\n",
      "F1 Score: 1.000\n",
      "--------------------------------------------------TOTAL 14 --------------------------------------------------\n",
      "Precision: 0.984\n",
      "Recall: 0.984\n",
      "F1 Score: 0.984\n"
     ]
    }
   ],
   "source": [
    "vul = \"RE\"\n",
    "data = \"Data\"\n",
    "data_path = f\"../../Dataset/{data}/{vul}\"\n",
    "result_path = os.path.join(data_path, \"buggy_result\")\n",
    "actual_data , invalid_files = read_json_files(result_path)\n",
    "gt_path = os.path.join(data_path, \"buggy_loc\")\n",
    "gt_data, _ = read_csv_files(gt_path)\n",
    "\n",
    "actual_lines = get_json_lines(actual_data)\n",
    "gt_lines = get_csv_lines(gt_data)\n",
    "actual_overlap, gt_found = check_enclosure(actual_lines, gt_lines)\n",
    "#actual_overlap = dict(sorted(actual_overlap.items()))\n",
    "for i, (key, actual_value) in enumerate(actual_overlap.items()):\n",
    "    print(25*\"-\"+key+25*\"-\")\n",
    "    gt_value = gt_found[key]\n",
    "    evaluator = evaluate(actual_value, gt_value)\n",
    "    evaluator.display()\n",
    "\n",
    "print(50*\"-\"+ \"TOTAL\", i+1,  50*\"-\")\n",
    "total_actual = [element for sublist in actual_overlap.values() for element in sublist]\n",
    "total_gt = [element for sublist in gt_found.values() for element in sublist]\n",
    "total_evaluator = evaluate(total_actual, total_gt)\n",
    "total_evaluator.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8993c530-84a8-48ac-9bd3-8ce1509c1bf5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0999ea63-a9bf-4d1d-a781-b26fde7e936f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c5e590-848a-4c58-9e54-591db4feb9f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8026497-5a33-4132-b598-0bfb6dbac56f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
