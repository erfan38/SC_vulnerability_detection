{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fd691b-2a3c-4d5e-9092-cd5bb5478668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df7a4c91-56ad-4ac1-8838-c3b3ee7d0c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comments removed. Cleaned file saved as: ../../Dataset/temp_dataset/clean_dataset/IoU/buggy_5_cleaned.sol\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_comments_from_solidity(file_path):\n",
    "    # Read the file content\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    # Define regex patterns for single-line and multi-line comments\n",
    "    single_line_comment_pattern = re.compile(r'//.*')\n",
    "    multi_line_comment_pattern = re.compile(r'/\\*.*?\\*/', re.DOTALL)\n",
    "    \n",
    "    # Remove single-line comments\n",
    "    content = re.sub(single_line_comment_pattern, '', content)\n",
    "    # Remove multi-line comments\n",
    "    content = re.sub(multi_line_comment_pattern, '', content)\n",
    "    \n",
    "    # Optional: Remove extra whitespace left by comments\n",
    "    content = re.sub(r'\\n\\s*\\n', '\\n', content)  # Remove extra newlines\n",
    "    content = content.strip()  # Remove leading/trailing whitespace\n",
    "    \n",
    "    # Write the cleaned content to a new file\n",
    "    cleaned_file_path = file_path.replace('.sol', '_cleaned.sol')\n",
    "    with open(cleaned_file_path, 'w') as cleaned_file:\n",
    "        cleaned_file.write(content)\n",
    "    \n",
    "    print(f\"Comments removed. Cleaned file saved as: {cleaned_file_path}\")\n",
    "\n",
    "data_loc = \"../../Dataset/temp_dataset/clean_dataset/IoU\"\n",
    "sol_file_name = \"buggy_5.sol\"\n",
    "with open(os.path.join(data_loc, sol_file_name), 'r') as file:\n",
    "    code = file.read()\n",
    "remove_comments_from_solidity(os.path.join(data_loc, sol_file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bcf9b93-7a09-409a-83f3-df32bf33ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def is_comment_line(line):\n",
    "    line = line.strip()\n",
    "    return line.startswith(\"//\") or line.startswith(\"/*\") or line.startswith(\"*\") or line.startswith(\"*/\") or line.startswith(\"///\") or line.startswith(\"/**\")\n",
    "\n",
    "def comment_dict_from_file(file_path):\n",
    "    comment_dict = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        in_multiline_comment = False\n",
    "        \n",
    "        for i, line in enumerate(lines, start=1):\n",
    "            stripped_line = line.strip()\n",
    "            \n",
    "            if stripped_line.startswith(\"/*\") or stripped_line.startswith(\"/**\"):\n",
    "                in_multiline_comment = True\n",
    "            \n",
    "            if in_multiline_comment or is_comment_line(stripped_line):\n",
    "                comment_dict[i] = True\n",
    "            else:\n",
    "                comment_dict[i] = False\n",
    "            \n",
    "            if in_multiline_comment and \"*/\" in stripped_line:\n",
    "                in_multiline_comment = False\n",
    "\n",
    "    return comment_dict\n",
    "\n",
    "def process_csv_and_save(input_csv, solidity_file, output_csv):\n",
    "    # Load CSV file\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Create comment dictionary from Solidity file\n",
    "    comment_dict = comment_dict_from_file(solidity_file)\n",
    "\n",
    "    # Calculate the number of True before each loc and subtract it\n",
    "    true_count = 0\n",
    "    result = []\n",
    "\n",
    "    for loc in df['loc']:\n",
    "        true_count = sum(1 for i in range(1, loc) if comment_dict.get(i, False))\n",
    "        result.append(loc - true_count)\n",
    "\n",
    "    # Add the new column to the DataFrame\n",
    "    df['adjusted_loc'] = result\n",
    "\n",
    "    # Save the new DataFrame to a new CSV file\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "# Usage\n",
    "input_csv = 'BugLog_1.csv'\n",
    "solidity_file = 'buggy_1.sol'\n",
    "output_csv = 'BugLog_1_updated.csv'\n",
    "\n",
    "process_csv_and_save(input_csv, solidity_file, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2c639ef-d6cc-4e39-bc8c-62f4dfac3bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def is_comment_line(line):\n",
    "    line = line.strip()\n",
    "    return line.startswith(\"//\") or line.startswith(\"/*\") or line.startswith(\"*/\") or line.startswith(\"///\") or line.startswith(\"/**\")\n",
    "\n",
    "def remove_comments_from_line(line):\n",
    "    # Remove single-line comments\n",
    "    line = re.sub(r'//.*', '', line)\n",
    "    # Remove multi-line comments within a line\n",
    "    line = re.sub(r'/\\*.*?\\*/', '', line, flags=re.DOTALL)\n",
    "    return line\n",
    "\n",
    "def process_solidity_file(file_path):\n",
    "    cleaned_lines = []\n",
    "    comment_lines = []\n",
    "    in_multiline_comment = False\n",
    "    code_started = False\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "        for i, line in enumerate(lines, start=1):\n",
    "            stripped_line = line.strip()\n",
    "            \n",
    "\n",
    "            # Handle multi-line comments\n",
    "            if in_multiline_comment:\n",
    "                comment_lines.append(i)\n",
    "                if \"*/\" in stripped_line:\n",
    "                    in_multiline_comment = False\n",
    "                continue\n",
    "\n",
    "            if stripped_line.startswith(\"/*\") or stripped_line.startswith(\"/**\"):\n",
    "                in_multiline_comment = True\n",
    "                comment_lines.append(i)\n",
    "                continue\n",
    "            \n",
    "            if is_comment_line(stripped_line):\n",
    "                comment_lines.append(i)\n",
    "                continue\n",
    "\n",
    "            # Check if code has started\n",
    "            if not code_started and stripped_line:\n",
    "                code_started = True\n",
    "                \n",
    "            if not code_started and not stripped_line:\n",
    "                comment_lines.append(i)\n",
    "                continue\n",
    "\n",
    "            cleaned_line = remove_comments_from_line(line)\n",
    "            cleaned_lines.append(cleaned_line)\n",
    "    \n",
    "    return cleaned_lines, comment_lines\n",
    "\n",
    "\n",
    "def save_cleaned_file(cleaned_lines, output_path):\n",
    "    with open(output_path, 'w') as file:\n",
    "        file.writelines(cleaned_lines)\n",
    "\n",
    "def process_csv_and_save(input_csv, comment_lines, output_csv):\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    new_locs = []\n",
    "    new_lengths = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        loc = row['loc']\n",
    "        length = row['length']\n",
    "        \n",
    "        true_count_before_loc = sum(1 for cl in comment_lines if cl < loc)\n",
    "        new_loc = loc - true_count_before_loc\n",
    "        new_locs.append(new_loc)\n",
    "\n",
    "        true_count_in_range = sum(1 for cl in comment_lines if loc <= cl < loc + length)\n",
    "        new_length = length - true_count_in_range\n",
    "        new_lengths.append(new_length)\n",
    "\n",
    "    df['loc'] = new_locs\n",
    "    df['length'] = new_lengths\n",
    "\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "def remove_initial_newlines(lines):\n",
    "    while lines and lines[0] == '\\n':\n",
    "        lines.pop(0)\n",
    "    return lines\n",
    "\n",
    "# solidity_file = 'buggy_1.sol'\n",
    "# cleaned_solidity_file = 'buggy_1_no_comments.sol'\n",
    "# input_csv = 'BugLog_1.csv'\n",
    "# output_csv = 'BugLog_1_updated.csv'\n",
    "\n",
    "# cleaned_lines, comment_lines = process_solidity_file(solidity_file)\n",
    "# save_cleaned_file(cleaned_lines, cleaned_solidity_file)\n",
    "# process_csv_and_save(input_csv, comment_lines, output_csv)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c72d4ce9-4c4f-4b05-be64-ff7fae444793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU\n",
      "RE\n",
      "TD\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pattern = r'^buggy_(\\d+)\\.sol$'\n",
    "\n",
    "i = 0\n",
    "for vul in ['IoU', 'RE', 'TD']:\n",
    "    print(vul)\n",
    "    data_loc = f\"../../Dataset/{vul}/SolidiFi_{vul}\"\n",
    "    out_doc = os.path.join(data_loc, \"draft\")\n",
    "    os.makedirs(out_doc, exist_ok=True)\n",
    "    \n",
    "    matching_files = []\n",
    "    for filename in os.listdir(data_loc):\n",
    "        match = re.match(pattern, filename)\n",
    "        if match:\n",
    "            number = match.group(1)\n",
    "            # print(filename)\n",
    "            matching_files.append(filename)\n",
    "            solidity_file = os.path.join(data_loc, filename)\n",
    "            cleaned_solidity_file = os.path.join(out_doc, f\"no-commented_{filename}\")    \n",
    "            input_csv = os.path.join(data_loc, f\"BugLog_{number}.csv\")\n",
    "            output_csv = os.path.join(out_doc, f\"no-commented_BugLog_{number}.csv\")  \n",
    "            cleaned_lines, comment_lines = process_solidity_file(solidity_file)\n",
    "            # cleaned_lines = remove_initial_newlines(cleaned_lines)\n",
    "            save_cleaned_file(cleaned_lines, cleaned_solidity_file)\n",
    "            process_csv_and_save(input_csv, comment_lines, output_csv)\n",
    "            i+=1\n",
    "            # print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "971a0583-9463-4127-a103-6b5acfcae7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generate_code import extract_code_blocks\n",
    "from generate_code import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef22aa79-eb4d-4ffc-9670-6d7a692111c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RE\n",
      "1 no-commented_buggy_16.sol\n",
      "2 no-commented_buggy_45.sol\n",
      "3 no-commented_buggy_47.sol\n",
      "4 no-commented_buggy_40.sol\n",
      "5 no-commented_buggy_27.sol\n",
      "6 no-commented_buggy_18.sol\n",
      "7 no-commented_buggy_30.sol\n",
      "8 no-commented_buggy_24.sol\n",
      "9 no-commented_buggy_31.sol\n",
      "10 no-commented_buggy_35.sol\n",
      "11 no-commented_buggy_21.sol\n",
      "12 no-commented_buggy_34.sol\n",
      "13 no-commented_buggy_22.sol\n",
      "14 no-commented_buggy_36.sol\n",
      "15 no-commented_buggy_23.sol\n",
      "______________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "def add_line_numbers(text):\n",
    "    lines = text.split('\\n')\n",
    "    numbered_lines = [f\"{i + 1}: {line}\" for i, line in enumerate(lines)]\n",
    "    numbered_text = '\\n'.join(numbered_lines)\n",
    "    return numbered_text\n",
    "\n",
    "\n",
    "rerun_files = [\"no-commented_buggy_16.sol\", \n",
    "               \"no-commented_buggy_18.sol\",\n",
    "               \"no-commented_buggy_21.sol\",\n",
    "               \"no-commented_buggy_22.sol\",\n",
    "               \"no-commented_buggy_23.sol\",\n",
    "               \"no-commented_buggy_24.sol\",\n",
    "               \"no-commented_buggy_27.sol\",\n",
    "               \"no-commented_buggy_30.sol\",\n",
    "               \"no-commented_buggy_31.sol\",\n",
    "               \"no-commented_buggy_34.sol\",\n",
    "               \"no-commented_buggy_35.sol\",\n",
    "               \"no-commented_buggy_36.sol\",\n",
    "               \"no-commented_buggy_40.sol\",\n",
    "               \"no-commented_buggy_45.sol\",\n",
    "               \"no-commented_buggy_47.sol\",\n",
    "               \n",
    "               \n",
    "              ]\n",
    "\n",
    "pattern = r'^no-commented_buggy_(\\d+)\\.sol$'\n",
    "\n",
    "for vul in ['RE']:#, 'RE', 'TD']:\n",
    "    print(vul)\n",
    "    renamer = Generator(\"renamer\", vul)\n",
    "    data_loc = f\"../../Dataset/{vul}/SolidiFi_{vul}/draft\"\n",
    "    # out_doc = os.path.join(data_loc, \"draft\")\n",
    "    os.makedirs(data_loc, exist_ok=True)\n",
    "    matching_files = []\n",
    "    count=0\n",
    "    for filename in os.listdir(data_loc):\n",
    "        if re.match(pattern, filename) and filename in rerun_files:\n",
    "            count+=1\n",
    "            print(count, filename)\n",
    "            matching_files.append(filename)\n",
    "            with open(os.path.join(data_loc, filename), 'r') as file:\n",
    "                code = file.read()\n",
    "            code = add_line_numbers(code)\n",
    "            renamed_uncommented_path = os.path.join(data_loc, f\"renamed_{filename}\")\n",
    "            if not os.path.exists(renamed_uncommented_path) and True:\n",
    "                renamer.create_prompt(example=[], instruction='', code=code)\n",
    "                messages = renamer.message\n",
    "                # print(messages)\n",
    "                \n",
    "                response, _ = renamer.generate()\n",
    "                code = extract_code_blocks(response)\n",
    "                with open(renamed_uncommented_path, 'w') as file:\n",
    "                    file.write(code)\n",
    "                # break\n",
    "            else: \n",
    "                continue\n",
    "            print(20*\"_\")\n",
    "    print(70*\"_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96182d4-c88a-460f-b458-9d16bf79fb04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_loc, filename), 'r') as file:\n",
    "    code = file.read()\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08acc8f9-e7db-45e7-98ee-a6a32828c8ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
