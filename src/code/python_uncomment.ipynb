{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fd691b-2a3c-4d5e-9092-cd5bb5478668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df7a4c91-56ad-4ac1-8838-c3b3ee7d0c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comments removed. Cleaned file saved as: ../../Dataset/temp_dataset/clean_dataset/IoU/buggy_5_cleaned.sol\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_comments_from_solidity(file_path):\n",
    "    # Read the file content\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    # Define regex patterns for single-line and multi-line comments\n",
    "    single_line_comment_pattern = re.compile(r'//.*')\n",
    "    multi_line_comment_pattern = re.compile(r'/\\*.*?\\*/', re.DOTALL)\n",
    "    \n",
    "    # Remove single-line comments\n",
    "    content = re.sub(single_line_comment_pattern, '', content)\n",
    "    # Remove multi-line comments\n",
    "    content = re.sub(multi_line_comment_pattern, '', content)\n",
    "    \n",
    "    # Optional: Remove extra whitespace left by comments\n",
    "    content = re.sub(r'\\n\\s*\\n', '\\n', content)  # Remove extra newlines\n",
    "    content = content.strip()  # Remove leading/trailing whitespace\n",
    "    \n",
    "    # Write the cleaned content to a new file\n",
    "    cleaned_file_path = file_path.replace('.sol', '_cleaned.sol')\n",
    "    with open(cleaned_file_path, 'w') as cleaned_file:\n",
    "        cleaned_file.write(content)\n",
    "    \n",
    "    print(f\"Comments removed. Cleaned file saved as: {cleaned_file_path}\")\n",
    "\n",
    "data_loc = \"../../Dataset/temp_dataset/clean_dataset/IoU\"\n",
    "sol_file_name = \"buggy_5.sol\"\n",
    "with open(os.path.join(data_loc, sol_file_name), 'r') as file:\n",
    "    code = file.read()\n",
    "remove_comments_from_solidity(os.path.join(data_loc, sol_file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bcf9b93-7a09-409a-83f3-df32bf33ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def is_comment_line(line):\n",
    "    line = line.strip()\n",
    "    return line.startswith(\"//\") or line.startswith(\"/*\") or line.startswith(\"*\") or line.startswith(\"*/\") or line.startswith(\"///\") or line.startswith(\"/**\")\n",
    "\n",
    "def comment_dict_from_file(file_path):\n",
    "    comment_dict = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        in_multiline_comment = False\n",
    "        \n",
    "        for i, line in enumerate(lines, start=1):\n",
    "            stripped_line = line.strip()\n",
    "            \n",
    "            if stripped_line.startswith(\"/*\") or stripped_line.startswith(\"/**\"):\n",
    "                in_multiline_comment = True\n",
    "            \n",
    "            if in_multiline_comment or is_comment_line(stripped_line):\n",
    "                comment_dict[i] = True\n",
    "            else:\n",
    "                comment_dict[i] = False\n",
    "            \n",
    "            if in_multiline_comment and \"*/\" in stripped_line:\n",
    "                in_multiline_comment = False\n",
    "\n",
    "    return comment_dict\n",
    "\n",
    "def process_csv_and_save(input_csv, solidity_file, output_csv):\n",
    "    # Load CSV file\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Create comment dictionary from Solidity file\n",
    "    comment_dict = comment_dict_from_file(solidity_file)\n",
    "\n",
    "    # Calculate the number of True before each loc and subtract it\n",
    "    true_count = 0\n",
    "    result = []\n",
    "\n",
    "    for loc in df['loc']:\n",
    "        true_count = sum(1 for i in range(1, loc) if comment_dict.get(i, False))\n",
    "        result.append(loc - true_count)\n",
    "\n",
    "    # Add the new column to the DataFrame\n",
    "    df['adjusted_loc'] = result\n",
    "\n",
    "    # Save the new DataFrame to a new CSV file\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "# Usage\n",
    "input_csv = 'BugLog_1.csv'\n",
    "solidity_file = 'buggy_1.sol'\n",
    "output_csv = 'BugLog_1_updated.csv'\n",
    "\n",
    "process_csv_and_save(input_csv, solidity_file, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2c639ef-d6cc-4e39-bc8c-62f4dfac3bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def is_comment_line(line):\n",
    "    line = line.strip()\n",
    "    return line.startswith(\"//\") or line.startswith(\"/*\") or line.startswith(\"*/\") or line.startswith(\"///\") or line.startswith(\"/**\")\n",
    "\n",
    "def remove_comments_from_line(line):\n",
    "    # Remove single-line comments\n",
    "    line = re.sub(r'//.*', '', line)\n",
    "    # Remove multi-line comments within a line\n",
    "    line = re.sub(r'/\\*.*?\\*/', '', line, flags=re.DOTALL)\n",
    "    return line\n",
    "\n",
    "def process_solidity_file(file_path):\n",
    "    cleaned_lines = []\n",
    "    comment_lines = []\n",
    "    in_multiline_comment = False\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "        for i, line in enumerate(lines, start=1):\n",
    "            stripped_line = line.strip()\n",
    "            \n",
    "            # Handle multi-line comments\n",
    "            if in_multiline_comment:\n",
    "                comment_lines.append(i)\n",
    "                if \"*/\" in stripped_line:\n",
    "                    in_multiline_comment = False\n",
    "                continue\n",
    "\n",
    "            if stripped_line.startswith(\"/*\") or stripped_line.startswith(\"/**\"):\n",
    "                in_multiline_comment = True\n",
    "                comment_lines.append(i)\n",
    "                continue\n",
    "            \n",
    "            if is_comment_line(stripped_line):\n",
    "                comment_lines.append(i)\n",
    "                continue\n",
    "            \n",
    "            cleaned_line = remove_comments_from_line(line)\n",
    "            cleaned_lines.append(cleaned_line)\n",
    "    \n",
    "    return cleaned_lines, comment_lines\n",
    "\n",
    "def save_cleaned_file(cleaned_lines, output_path):\n",
    "    with open(output_path, 'w') as file:\n",
    "        file.writelines(cleaned_lines)\n",
    "\n",
    "def process_csv_and_save(input_csv, comment_lines, output_csv):\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    new_locs = []\n",
    "    new_lengths = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        loc = row['loc']\n",
    "        length = row['length']\n",
    "        \n",
    "        true_count_before_loc = sum(1 for cl in comment_lines if cl < loc)\n",
    "        new_loc = loc - true_count_before_loc\n",
    "        new_locs.append(new_loc)\n",
    "\n",
    "        true_count_in_range = sum(1 for cl in comment_lines if loc <= cl < loc + length)\n",
    "        new_length = length - true_count_in_range\n",
    "        new_lengths.append(new_length)\n",
    "\n",
    "    df['loc'] = new_locs\n",
    "    df['length'] = new_lengths\n",
    "\n",
    "    df.to_csv(output_csv, index=False)\n",
    "\n",
    "\n",
    "\n",
    "solidity_file = 'buggy_1.sol'\n",
    "cleaned_solidity_file = 'buggy_1_no_comments.sol'\n",
    "input_csv = 'BugLog_1.csv'\n",
    "output_csv = 'BugLog_1_updated.csv'\n",
    "\n",
    "cleaned_lines, comment_lines = process_solidity_file(solidity_file)\n",
    "save_cleaned_file(cleaned_lines, cleaned_solidity_file)\n",
    "process_csv_and_save(input_csv, comment_lines, output_csv)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c72d4ce9-4c4f-4b05-be64-ff7fae444793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU\n",
      "buggy_19.sol\n",
      "\n",
      "buggy_31.sol\n",
      "\n",
      "buggy_25.sol\n",
      "\n",
      "buggy_24.sol\n",
      "\n",
      "buggy_30.sol\n",
      "\n",
      "buggy_18.sol\n",
      "\n",
      "buggy_1.sol\n",
      "\n",
      "buggy_3.sol\n",
      "\n",
      "buggy_26.sol\n",
      "\n",
      "buggy_32.sol\n",
      "\n",
      "buggy_33.sol\n",
      "\n",
      "buggy_27.sol\n",
      "\n",
      "buggy_2.sol\n",
      "\n",
      "buggy_6.sol\n",
      "\n",
      "buggy_23.sol\n",
      "\n",
      "buggy_37.sol\n",
      "\n",
      "buggy_36.sol\n",
      "\n",
      "buggy_22.sol\n",
      "\n",
      "buggy_7.sol\n",
      "\n",
      "buggy_5.sol\n",
      "\n",
      "buggy_34.sol\n",
      "\n",
      "buggy_20.sol\n",
      "\n",
      "buggy_21.sol\n",
      "\n",
      "buggy_35.sol\n",
      "\n",
      "buggy_4.sol\n",
      "\n",
      "buggy_46.sol\n",
      "\n",
      "buggy_47.sol\n",
      "\n",
      "buggy_45.sol\n",
      "\n",
      "buggy_50.sol\n",
      "\n",
      "buggy_44.sol\n",
      "\n",
      "buggy_40.sol\n",
      "\n",
      "buggy_41.sol\n",
      "\n",
      "buggy_43.sol\n",
      "\n",
      "buggy_42.sol\n",
      "\n",
      "buggy_49.sol\n",
      "\n",
      "buggy_48.sol\n",
      "\n",
      "buggy_9.sol\n",
      "\n",
      "buggy_38.sol\n",
      "\n",
      "buggy_10.sol\n",
      "\n",
      "buggy_11.sol\n",
      "\n",
      "buggy_39.sol\n",
      "\n",
      "buggy_8.sol\n",
      "\n",
      "buggy_13.sol\n",
      "\n",
      "buggy_12.sol\n",
      "\n",
      "buggy_16.sol\n",
      "\n",
      "buggy_17.sol\n",
      "\n",
      "buggy_15.sol\n",
      "\n",
      "buggy_29.sol\n",
      "\n",
      "buggy_28.sol\n",
      "\n",
      "buggy_14.sol\n",
      "\n",
      "RE\n",
      "buggy_19.sol\n",
      "\n",
      "buggy_31.sol\n",
      "\n",
      "buggy_25.sol\n",
      "\n",
      "buggy_24.sol\n",
      "\n",
      "buggy_30.sol\n",
      "\n",
      "buggy_18.sol\n",
      "\n",
      "buggy_1.sol\n",
      "\n",
      "buggy_3.sol\n",
      "\n",
      "buggy_26.sol\n",
      "\n",
      "buggy_32.sol\n",
      "\n",
      "buggy_33.sol\n",
      "\n",
      "buggy_27.sol\n",
      "\n",
      "buggy_2.sol\n",
      "\n",
      "buggy_6.sol\n",
      "\n",
      "buggy_23.sol\n",
      "\n",
      "buggy_37.sol\n",
      "\n",
      "buggy_36.sol\n",
      "\n",
      "buggy_22.sol\n",
      "\n",
      "buggy_7.sol\n",
      "\n",
      "buggy_5.sol\n",
      "\n",
      "buggy_34.sol\n",
      "\n",
      "buggy_20.sol\n",
      "\n",
      "buggy_21.sol\n",
      "\n",
      "buggy_35.sol\n",
      "\n",
      "buggy_4.sol\n",
      "\n",
      "buggy_46.sol\n",
      "\n",
      "buggy_47.sol\n",
      "\n",
      "buggy_45.sol\n",
      "\n",
      "buggy_50.sol\n",
      "\n",
      "buggy_44.sol\n",
      "\n",
      "buggy_40.sol\n",
      "\n",
      "buggy_41.sol\n",
      "\n",
      "buggy_43.sol\n",
      "\n",
      "buggy_42.sol\n",
      "\n",
      "buggy_49.sol\n",
      "\n",
      "buggy_48.sol\n",
      "\n",
      "buggy_9.sol\n",
      "\n",
      "buggy_38.sol\n",
      "\n",
      "buggy_10.sol\n",
      "\n",
      "buggy_11.sol\n",
      "\n",
      "buggy_39.sol\n",
      "\n",
      "buggy_8.sol\n",
      "\n",
      "buggy_13.sol\n",
      "\n",
      "buggy_12.sol\n",
      "\n",
      "buggy_16.sol\n",
      "\n",
      "buggy_17.sol\n",
      "\n",
      "buggy_15.sol\n",
      "\n",
      "buggy_29.sol\n",
      "\n",
      "buggy_28.sol\n",
      "\n",
      "buggy_14.sol\n",
      "\n",
      "TD\n",
      "buggy_19.sol\n",
      "\n",
      "buggy_31.sol\n",
      "\n",
      "buggy_25.sol\n",
      "\n",
      "buggy_24.sol\n",
      "\n",
      "buggy_30.sol\n",
      "\n",
      "buggy_18.sol\n",
      "\n",
      "buggy_1.sol\n",
      "\n",
      "buggy_3.sol\n",
      "\n",
      "buggy_26.sol\n",
      "\n",
      "buggy_32.sol\n",
      "\n",
      "buggy_33.sol\n",
      "\n",
      "buggy_27.sol\n",
      "\n",
      "buggy_2.sol\n",
      "\n",
      "buggy_6.sol\n",
      "\n",
      "buggy_23.sol\n",
      "\n",
      "buggy_37.sol\n",
      "\n",
      "buggy_36.sol\n",
      "\n",
      "buggy_22.sol\n",
      "\n",
      "buggy_7.sol\n",
      "\n",
      "buggy_5.sol\n",
      "\n",
      "buggy_34.sol\n",
      "\n",
      "buggy_20.sol\n",
      "\n",
      "buggy_21.sol\n",
      "\n",
      "buggy_35.sol\n",
      "\n",
      "buggy_4.sol\n",
      "\n",
      "buggy_46.sol\n",
      "\n",
      "buggy_47.sol\n",
      "\n",
      "buggy_45.sol\n",
      "\n",
      "buggy_50.sol\n",
      "\n",
      "buggy_44.sol\n",
      "\n",
      "buggy_40.sol\n",
      "\n",
      "buggy_41.sol\n",
      "\n",
      "buggy_43.sol\n",
      "\n",
      "buggy_42.sol\n",
      "\n",
      "buggy_49.sol\n",
      "\n",
      "buggy_48.sol\n",
      "\n",
      "buggy_9.sol\n",
      "\n",
      "buggy_38.sol\n",
      "\n",
      "buggy_10.sol\n",
      "\n",
      "buggy_11.sol\n",
      "\n",
      "buggy_39.sol\n",
      "\n",
      "buggy_8.sol\n",
      "\n",
      "buggy_13.sol\n",
      "\n",
      "buggy_12.sol\n",
      "\n",
      "buggy_16.sol\n",
      "\n",
      "buggy_17.sol\n",
      "\n",
      "buggy_15.sol\n",
      "\n",
      "buggy_29.sol\n",
      "\n",
      "buggy_28.sol\n",
      "\n",
      "buggy_14.sol\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pattern = r'^buggy_(\\d+)\\.sol$'\n",
    "\n",
    "for vul in ['IoU', 'RE', 'TD']:\n",
    "    print(vul)\n",
    "    data_loc = f\"../../Dataset/{vul}/SolidiFi_{vul}\"\n",
    "    out_doc = os.path.join(data_loc, \"draft\")\n",
    "    os.makedirs(out_doc, exist_ok=True)\n",
    "    \n",
    "    matching_files = []\n",
    "    for filename in os.listdir(data_loc):\n",
    "        match = re.match(pattern, filename)\n",
    "        if match:\n",
    "            number = match.group(1)\n",
    "            print(filename)\n",
    "            matching_files.append(filename)\n",
    "            solidity_file = os.path.join(data_loc, filename)\n",
    "            cleaned_solidity_file = os.path.join(out_doc, f\"no-commented_{filename}\")    \n",
    "            input_csv = os.path.join(data_loc, f\"BugLog_{number}.csv\")\n",
    "            output_csv = os.path.join(out_doc, f\"no-commented_BugLog_{number}.csv\")  \n",
    "            cleaned_lines, comment_lines = process_solidity_file(solidity_file)\n",
    "            save_cleaned_file(cleaned_lines, cleaned_solidity_file)\n",
    "            process_csv_and_save(input_csv, comment_lines, output_csv)\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef22aa79-eb4d-4ffc-9670-6d7a692111c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
